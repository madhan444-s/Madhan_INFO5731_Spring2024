{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhan444-s/Madhan_INFO5731_Spring2024/blob/main/Dadi_Madhan_Exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Sentiment analysis of messages on social media could be an intriguing text classification assignment. Finding the sentiment—whether good, negative, or neutral—expressed in a text is the goal of sentiment analysis. Understanding consumer mood, industry trends, and brand impression may all be gained by examining social media sentiment analysis. The following list contains five different feature types that could be helpful in creating a sentiment analysis machine learning model:\n",
        "\n",
        "1. Bag-of-Words (BoW) or Term Frequency-Inverse Document Frequency (TF-IDF):\n",
        "    The text's word frequencies or TF-IDF scores for every word.\n",
        "BoW and TF-IDF assess a word's significance in a document. When expressing feeling, words with greater frequencies or TF-IDF scores may be quite important.\n",
        "\n",
        "2. N-grams:\n",
        "   Adjacent word sequences (bigrams or trigrams).\n",
        "N-grams depict the relationships and context of words. Phrases such as \"very good\" or \"not happy\" have a different effect on sentiment than single words.\n",
        "\n",
        "3. Part-of-Speech (POS) Tags:\n",
        "  Verbs, adjectives, and other POS markers are distributed throughout the text.\n",
        "Sentiment may be influenced differently by various POS tags. Adjectives and verbs, for example, could convey more feeling than nouns.\n",
        "\n",
        "4. Emotion Lexicons:\n",
        "    The existence or occurrence of terms linked to certain feelings (such happiness, sorrow, or fury).\n",
        "Lexicons of emotions aid in expressing the text's emotional tone. The feeling conveyed in the material might be powerfully indicated by certain emotive terms.\n",
        "\n",
        "5. Sentiment Lexicons:\n",
        "    The existence or occurrence of terms linked to certain feelings (such happiness, sorrow, or fury).\n",
        "Lexicons of emotions aid in expressing the text's emotional tone. The feeling conveyed in the material might be powerfully indicated by certain emotive terms.\n",
        "\n",
        "Collectively, these attributes give a rich representation of the textual material, allowing the machine learning model to understand patterns and produce accurate sentiment predictions. Using a combination of these feature categories can improve the model's capacity to capture subtle expressions in social media text.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea4b9c5-683e-4051-e83f-9e16783e1850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Features:\n",
            "   amazing  anyone  bad  buy  disappointed  enjoyed  every  good  great  is  \\\n",
            "0        1       0    0    0             0        0      0     0      0   0   \n",
            "1        0       0    0    0             1        0      0     0      0   0   \n",
            "2        0       0    1    0             0        0      0     1      0   1   \n",
            "3        0       1    0    1             0        0      0     0      0   0   \n",
            "4        0       0    0    0             0        1      1     0      1   1   \n",
            "\n",
            "   ...  terrible  the  this  today  very  was  waste  weather  why  would  \n",
            "0  ...         0    0     1      0     0    0      0        0    0      0  \n",
            "1  ...         1    1     0      0     1    1      0        0    0      0  \n",
            "2  ...         0    1     0      1     0    0      0        1    0      0  \n",
            "3  ...         0    0     1      0     0    0      1        0    1      1  \n",
            "4  ...         0    0     1      0     0    0      0        0    0      0  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "TF-IDF Features:\n",
            "    amazing    anyone      bad       buy  disappointed   enjoyed     every  \\\n",
            "0  0.506563  0.000000  0.00000  0.000000      0.000000  0.000000  0.000000   \n",
            "1  0.000000  0.000000  0.00000  0.000000      0.420669  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.37007  0.000000      0.000000  0.000000  0.000000   \n",
            "3  0.000000  0.323627  0.00000  0.323627      0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  0.00000  0.000000      0.000000  0.372708  0.372708   \n",
            "\n",
            "      good     great        is  ...  terrible       the      this    today  \\\n",
            "0  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.339251  0.00000   \n",
            "1  0.00000  0.000000  0.000000  ...  0.420669  0.339393  0.000000  0.00000   \n",
            "2  0.37007  0.000000  0.298570  ...  0.000000  0.298570  0.000000  0.37007   \n",
            "3  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.216737  0.00000   \n",
            "4  0.00000  0.372708  0.300698  ...  0.000000  0.000000  0.249607  0.00000   \n",
            "\n",
            "       very       was     waste  weather       why     would  \n",
            "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  \n",
            "1  0.420669  0.420669  0.000000  0.00000  0.000000  0.000000  \n",
            "2  0.000000  0.000000  0.000000  0.37007  0.000000  0.000000  \n",
            "3  0.000000  0.000000  0.323627  0.00000  0.323627  0.323627  \n",
            "4  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "N-grams Features:\n",
            "[('I', 'love'), ('love', 'this'), ('this', 'product'), ('product', '.'), ('.', 'It'), ('It', \"'s\"), (\"'s\", 'amazing'), ('amazing', '!'), ('The', 'service'), ('service', 'was'), ('was', 'terrible'), ('terrible', '.'), ('.', 'I'), ('I', \"'m\"), (\"'m\", 'very'), ('very', 'disappointed'), ('disappointed', '.'), ('The', 'weather'), ('weather', 'today'), ('today', 'is'), ('is', 'neither'), ('neither', 'good'), ('good', 'nor'), ('nor', 'bad'), ('bad', '.'), ('Not', 'sure'), ('sure', 'why'), ('why', 'anyone'), ('anyone', 'would'), ('would', 'buy'), ('buy', 'this'), ('this', '.'), ('.', 'It'), ('It', \"'s\"), (\"'s\", 'a'), ('a', 'waste'), ('waste', 'of'), ('of', 'money'), ('money', '.'), ('This', 'movie'), ('movie', 'is'), ('is', 'great'), ('great', '.'), ('.', 'I'), ('I', 'enjoyed'), ('enjoyed', 'every'), ('every', 'moment'), ('moment', 'of'), ('of', 'it'), ('it', '.')]\n",
            "\n",
            "Part-of-Speech (POS) Tags Features:\n",
            "[('I', 'PRP'), ('love', 'VBP'), ('this', 'DT'), ('product', 'NN'), ('.', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('amazing', 'JJ'), ('!', '.'), ('The', 'DT'), ('service', 'NN'), ('was', 'VBD'), ('terrible', 'JJ'), ('.', '.'), ('I', 'PRP'), (\"'m\", 'VBP'), ('very', 'RB'), ('disappointed', 'JJ'), ('.', '.'), ('The', 'DT'), ('weather', 'NN'), ('today', 'NN'), ('is', 'VBZ'), ('neither', 'RB'), ('good', 'JJ'), ('nor', 'CC'), ('bad', 'JJ'), ('.', '.'), ('Not', 'RB'), ('sure', 'JJ'), ('why', 'WRB'), ('anyone', 'NN'), ('would', 'MD'), ('buy', 'VB'), ('this', 'DT'), ('.', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('waste', 'NN'), ('of', 'IN'), ('money', 'NN'), ('.', '.'), ('This', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('great', 'JJ'), ('.', '.'), ('I', 'PRP'), ('enjoyed', 'VBD'), ('every', 'DT'), ('moment', 'NN'), ('of', 'IN'), ('it', 'PRP'), ('.', '.')]\n",
            "\n",
            "Emotion Lexicons Features:\n",
            "   Positive_Count  Negative_Count\n",
            "0               2               0\n",
            "1               0               2\n",
            "2               1               1\n",
            "3               0               1\n",
            "4               1               0\n",
            "\n",
            "Sentiment Lexicons Features:\n",
            "   Positive_Count  Negative_Count\n",
            "0               2               0\n",
            "1               0               2\n",
            "2               1               1\n",
            "3               0               1\n",
            "4               1               0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# !pip install nltk\n",
        "# !python -m nltk.downloader punkt\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import gensim  # Add this line to import gensim\n",
        "\n",
        "# Download NLTK resource for part-of-speech tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Sample text data\n",
        "sample_data = [\n",
        "    \"I love this product. It's amazing!\",\n",
        "    \"The service was terrible. I'm very disappointed.\",\n",
        "    \"The weather today is neither good nor bad.\",\n",
        "    \"Not sure why anyone would buy this. It's a waste of money.\",\n",
        "    \"This movie is great. I enjoyed every moment of it.\"\n",
        "]\n",
        "\n",
        "# Function to extract Bag-of-Words (BoW) or Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "def extract_bow_tfidf(texts, method='bow'):\n",
        "    if method == 'bow':\n",
        "        vectorizer = CountVectorizer()\n",
        "    elif method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "\n",
        "    features = vectorizer.fit_transform(texts)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    return pd.DataFrame(features.toarray(), columns=feature_names)\n",
        "\n",
        "# Function to extract N-grams\n",
        "def extract_ngrams(texts, n=2):\n",
        "    ngrams_list = []\n",
        "\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        ngrams_list.extend(ngrams(words, n))\n",
        "\n",
        "    return ngrams_list\n",
        "\n",
        "# Function to extract Part-of-Speech (POS) Tags\n",
        "def extract_pos_tags(texts):\n",
        "    pos_tags_list = []\n",
        "\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        pos_tags = pos_tag(words)\n",
        "        pos_tags_list.extend(pos_tags)\n",
        "\n",
        "    return pos_tags_list\n",
        "\n",
        "# Function to extract Emotion Lexicons\n",
        "def extract_emotion_lexicons(texts):\n",
        "    # Assume a simple list of positive and negative emotion words\n",
        "    positive_emotion_words = [\"love\", \"amazing\", \"joy\", \"good\", \"great\"]\n",
        "    negative_emotion_words = [\"terrible\", \"disappointed\", \"bad\", \"waste\"]\n",
        "\n",
        "    emotion_features = []\n",
        "\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        positive_count = sum(1 for word in words if word in positive_emotion_words)\n",
        "        negative_count = sum(1 for word in words if word in negative_emotion_words)\n",
        "        emotion_features.append({'Positive_Count': positive_count, 'Negative_Count': negative_count})\n",
        "\n",
        "    return pd.DataFrame(emotion_features)\n",
        "\n",
        "# Function to extract Sentiment Lexicons\n",
        "def extract_sentiment_lexicons(texts):\n",
        "    # Assume a simple list of positive and negative sentiment words\n",
        "    positive_sentiment_words = [\"love\", \"amazing\", \"joy\", \"good\", \"great\"]\n",
        "    negative_sentiment_words = [\"terrible\", \"disappointed\", \"bad\", \"waste\"]\n",
        "\n",
        "    sentiment_features = []\n",
        "\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        positive_count = sum(1 for word in words if word in positive_sentiment_words)\n",
        "        negative_count = sum(1 for word in words if word in negative_sentiment_words)\n",
        "        sentiment_features.append({'Positive_Count': positive_count, 'Negative_Count': negative_count})\n",
        "\n",
        "    return pd.DataFrame(sentiment_features)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Extracting features\n",
        "    bow_features = extract_bow_tfidf(sample_data, method='bow')\n",
        "    tfidf_features = extract_bow_tfidf(sample_data, method='tfidf')\n",
        "    ngrams_features = extract_ngrams(sample_data, n=2)\n",
        "    pos_tags_features = extract_pos_tags(sample_data)\n",
        "    emotion_lexicons_features = extract_emotion_lexicons(sample_data)\n",
        "    sentiment_lexicons_features = extract_sentiment_lexicons(sample_data)\n",
        "\n",
        "    # Displaying extracted features\n",
        "    print(\"Bag-of-Words Features:\")\n",
        "    print(bow_features)\n",
        "\n",
        "    print(\"\\nTF-IDF Features:\")\n",
        "    print(tfidf_features)\n",
        "\n",
        "    print(\"\\nN-grams Features:\")\n",
        "    print(ngrams_features)\n",
        "\n",
        "    print(\"\\nPart-of-Speech (POS) Tags Features:\")\n",
        "    print(pos_tags_features)\n",
        "\n",
        "    print(\"\\nEmotion Lexicons Features:\")\n",
        "    print(emotion_lexicons_features)\n",
        "\n",
        "    print(\"\\nSentiment Lexicons Features:\")\n",
        "    print(sentiment_lexicons_features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "f2a330c3-f2e8-4d81-91cd-22424cad6ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHere are the most important features based on the paper, ranked in descending order:\\n1. Document Frequency (DF): It is the number of documents in the corpus that contain the term.\\n2. TF-IDF: This method takes into account both term frequency (TF) and inverse document frequency (IDF) to measure the importance of a term.\\n3. Mutual Information (MI): It measures the mutual dependency between two variables.\\n4. Information Gain (IG): It is used to measure the dependence between features and class labels.\\n5. χ2 (CHI): It measures the degree of independence between a term and a category.\\n6. Correlation Coefficient (CC): It is a variant of the CHI measure.\\nOthers: The paper also mentions other methods like Term ReLatedness (TRL), CMFS, Distinguishing Feature Selector (DFS), SpreadFx, Bi-Normal Separation (BNS), Maximum Discrimination (MD), Linear Measure (LM), Posterior Inclusion Probability (PIP), IGFSS, Subspace Sample (SS), Weight-based Sampling (WS), Uniform Sampling (US), and Best Terms (BT).\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "'''\n",
        "Here are the most important features based on the paper, ranked in descending order:\n",
        "1. Document Frequency (DF): It is the number of documents in the corpus that contain the term.\n",
        "2. TF-IDF: This method takes into account both term frequency (TF) and inverse document frequency (IDF) to measure the importance of a term.\n",
        "3. Mutual Information (MI): It measures the mutual dependency between two variables.\n",
        "4. Information Gain (IG): It is used to measure the dependence between features and class labels.\n",
        "5. χ2 (CHI): It measures the degree of independence between a term and a category.\n",
        "6. Correlation Coefficient (CC): It is a variant of the CHI measure.\n",
        "Others: The paper also mentions other methods like Term ReLatedness (TRL), CMFS, Distinguishing Feature Selector (DFS), SpreadFx, Bi-Normal Separation (BNS), Maximum Discrimination (MD), Linear Measure (LM), Posterior Inclusion Probability (PIP), IGFSS, Subspace Sample (SS), Weight-based Sampling (WS), Uniform Sampling (US), and Best Terms (BT).\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "eea34367-4272-4d82-c136-895a10c5d542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Cosine_Similarity\n",
              "0                 I love this product. It's amazing!           0.404019\n",
              "3  Not sure why anyone would buy this. It's a was...           0.311158\n",
              "4  This movie is great. I enjoyed every moment of...           0.056885\n",
              "2         The weather today is neither good nor bad.          -0.024932\n",
              "1   The service was terrible. I'm very disappointed.          -0.063588"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-019ca209-5122-46ec-a643-764c19784644\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Cosine_Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this product. It's amazing!</td>\n",
              "      <td>0.404019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not sure why anyone would buy this. It's a was...</td>\n",
              "      <td>0.311158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This movie is great. I enjoyed every moment of...</td>\n",
              "      <td>0.056885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The weather today is neither good nor bad.</td>\n",
              "      <td>-0.024932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The service was terrible. I'm very disappointed.</td>\n",
              "      <td>-0.063588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-019ca209-5122-46ec-a643-764c19784644')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-019ca209-5122-46ec-a643-764c19784644 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-019ca209-5122-46ec-a643-764c19784644');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5b73191-9c9c-46d5-9616-cbcb90677805\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5b73191-9c9c-46d5-9616-cbcb90677805')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5b73191-9c9c-46d5-9616-cbcb90677805 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3caa8741-39ef-408b-a618-f1fb511bf6d3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3caa8741-39ef-408b-a618-f1fb511bf6d3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Not sure why anyone would buy this. It's a waste of money.\",\n          \"The service was terrible. I'm very disappointed.\",\n          \"This movie is great. I enjoyed every moment of it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cosine_Similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3111576437950134,\n          -0.0635879784822464,\n          0.05688505247235298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Install the necessary library\n",
        "!pip install sentence_transformers\n",
        "\n",
        "# Import libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Sample text data\n",
        "sample_data = [\n",
        "    \"I love this product. It's amazing!\",\n",
        "    \"The service was terrible. I'm very disappointed.\",\n",
        "    \"The weather today is neither good nor bad.\",\n",
        "    \"Not sure why anyone would buy this. It's a waste of money.\",\n",
        "    \"This movie is great. I enjoyed every moment of it.\"\n",
        "]\n",
        "\n",
        "# Sample query\n",
        "query = \"I want to purchase a good product. What are the best options?\"\n",
        "\n",
        "# Load a pre-trained BERT-based model (you can choose a different model if needed)\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Encode the query and sample data\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "sample_data_embeddings = model.encode(sample_data, convert_to_tensor=True)\n",
        "\n",
        "# Reshape the 1D array to 2D array\n",
        "query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "# Calculate cosine similarity between the query and each text in the data\n",
        "cosine_similarities = cosine_similarity(query_embedding, sample_data_embeddings).flatten()\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "result_df = pd.DataFrame({'Text': sample_data, 'Cosine_Similarity': cosine_similarities})\n",
        "\n",
        "# Rank the results based on cosine similarity in descending order\n",
        "result_df = result_df.sort_values(by='Cosine_Similarity', ascending=False)\n",
        "\n",
        "# Display the result DataFrame\n",
        "result_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The exercise provided a valuable learning experience in extracting features from text data for NLP.\n",
        "Key concepts like Bag-of-Words, TF-IDF, N-grams, POS tagging, and sentiment lexicons were well-covered, enhancing understanding.\n",
        "Challenges included environment setup and library installations, particularly with pre-trained models.\n",
        "The relevance to NLP is significant, as feature extraction is foundational for tasks like sentiment analysis, text classification, and information retrieval.\n",
        "The exercise offered practical insights applicable to real-world NLP scenarios.\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "70543e60-33e3-4e06-f463-f57550678c69"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\n\\nThe exercise provided a valuable learning experience in extracting features from text data for NLP.\\nKey concepts like Bag-of-Words, TF-IDF, N-grams, POS tagging, and sentiment lexicons were well-covered, enhancing understanding.\\nChallenges included environment setup and library installations, particularly with pre-trained models. \\nThe relevance to NLP is significant, as feature extraction is foundational for tasks like sentiment analysis, text classification, and information retrieval.\\nThe exercise offered practical insights applicable to real-world NLP scenarios.\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}